Overview:
# High Performance Computing: Classification Models
Detailed Explanation:

## Overview:

High Performance Computing (HPC) is a field that involves the use of powerful processors or a network of computers to perform complex computational tasks. The classification models in HPC help in understanding the different ways computers are designed to process information. The architectural schemes like Flynn's, Shore's, Feng's, Handler's and memory access like Shared Memory, Distributed Memory, Hybrid Distributed Shared Memory are essential to understand the functioning and design of HPC systems.

## Details:

### 1. Architectural Schemes

#### **1.1 Flynn's Taxonomy**

Flynn's Taxonomy is a classification for computer architectures proposed by Michael J. Flynn. It classifies the computer architectures based on the number of instruction streams and data streams available in the architecture.

- **Single Instruction, Single Data (SISD)**: A single processor executes a single instruction stream to manipulate data stored in a single memory. This is the traditional sequential or Von Neumann model.
- **Single Instruction, Multiple Data (SIMD)**: A single instruction stream is used to manipulate multiple data streams. This is typical of array processors and vector processors.
- **Multiple Instruction, Single Data (MISD)**: Multiple processors manipulate a single data stream. This is a rare category.
- **Multiple Instruction, Multiple Data (MIMD)**: Multiple autonomous processors simultaneously executing different instructions on different data. Most modern computers fall into this category.

#### **1.2 Shore's Taxonomy**

Shore's Taxonomy is a classification that further refines Flynn's Taxonomy by considering the issue of synchrony and control structures.

#### **1.3 Feng's Taxonomy**

Feng's Taxonomy is a classification that takes into consideration the data access and data manipulation capabilities of the computer architecture.

#### **1.4 Handler's Taxonomy**

Handler's Taxonomy is a classification that categorizes computer architectures based on the data type, structure, and number of instruction and data streams.

### 2. Memory Access

#### **2.1 Shared Memory**

Shared Memory systems have multiple processors that share a common, central memory. All processors can access all memory as global address space.

- **Uniform Memory Access (UMA)**: Every processor shares the physical memory uniformly. Processors access memory locations in any order.
- **Non-Uniform Memory Access (NUMA)**: Memory access time depends on the memory location relative to a processor. For local access, it's faster than for non-local access.

#### **2.2 Distributed Memory**

Distributed Memory systems have each processor having its own private memory. Computational memory is distributed among the processors.

#### **2.3 Hybrid Distributed Shared Memory**

Hybrid Distributed Shared Memory is a combination of shared and distributed memory systems. It takes advantage of both local and global memory accesses.

In conclusion, understanding these classification models and memory access methods is crucial in the field of High Performance Computing for designing and optimizing computational tasks.