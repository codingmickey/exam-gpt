Overview:
# High Performance Computing: Gustavson's Law
Detailed Explanation:

## Overview:

Gustavson's Law, proposed by John L. Gustavson, is a principle in computer science that is used to determine the scalability of parallel computing systems. It presents a more realistic and optimistic view of the potential gains from parallel computing compared to Amdahl's Law.

Gustavson's Law states that a system can effectively use increased parallelism even if a proportion of the system remains serial. This is because the workload can be expanded to fill the available parallelism.

## Details:

### Gustavson's Law

**Gustavson's Law** is formulated as follows:

*S' = S + P*(1 - S/N)*

Where:
- S' is the new speedup
- S is the serial portion of the code
- P is the parallel portion of the code
- N is the number of processors

This law assumes that the problem size increases proportionally with the number of processors, which means that the workload can be expanded to fill the available parallelism.

### Comparison with Amdahl's Law

Gustavson's Law is often compared to **Amdahl's Law**, another principle in computer science that is used to find the maximum improvement possible by just improving a portion of a system.

Amdahl's Law is more pessimistic than Gustavson's Law. It assumes a fixed problem size and states that the speedup of a program using multiple processors is limited by the time needed for the sequential fraction of the program.

### Implications of Gustavson's Law

The implications of Gustavson's Law are significant for the design and use of parallel computing systems. It suggests that as long as there is enough work to keep all processors busy, the system can effectively use increased parallelism, even if a proportion of the system remains serial.

This also means that the potential gains from parallel computing are not necessarily limited by the proportion of the system that cannot be parallelized, as suggested by Amdahl's Law.

### Example

Let's consider a program where S = 0.1 (10% of the time is spent on serial parts), and P = 0.9 (90% of the time is spent on parallel parts), and we have N = 4 processors.

According to Gustavson's Law, the speedup would be:

S' = S + P*(1 - S/N) = 0.1 + 0.9*(1 - 0.1/4) = 1.175

This means that the program would be 1.175 times faster using 4 processors compared to using a single processor.